{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "appfigures"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install selenium\n",
        "%pip install webdriver-manager\n",
        "%pip install bs4\n",
        "%pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "va5OqGldmavF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1727442580576,
          "user_tz": -120,
          "elapsed": 17594,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "315f2f6f-af2d-4bf2-cc0a-5bede929e774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.25.0 trio-0.26.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (2024.8.30)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Setup Chrome options\n",
        "options = Options()\n",
        "options.add_argument('--headless')  # Run in headless mode (no GUI)\n",
        "options.add_argument('--disable-gpu')\n",
        "options.add_argument('--window-size=1920x1080')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# Initialize the web driver with options\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# URL for scraping\n",
        "base_url = \"https://appfigures.com/top-apps/ios-app-store/united-states/iphone/top-free\"\n",
        "scraped_data = []\n",
        "\n",
        "# Visit the scraping URL\n",
        "driver.get(base_url)\n",
        "time.sleep(5)  # Initial wait for the page to load\n",
        "\n",
        "# Scroll parameters\n",
        "SCROLL_PAUSE_TIME = 1\n",
        "SCROLL_INCREMENT = 300  # Amount to scroll down each time\n",
        "MAX_ATTEMPTS = 20  # Max attempts to scroll and load more content\n",
        "\n",
        "# Function to get current number of loaded app elements\n",
        "def get_current_app_elements():\n",
        "    return driver.find_elements(By.XPATH, '//*[@id=\"app-root\"]/span/div[4]//div[contains(@class, \"s-1362551351-0\")]')\n",
        "\n",
        "# Scroll down in small increments to load all apps\n",
        "previous_data_count = 0\n",
        "attempts = 0\n",
        "\n",
        "while attempts < MAX_ATTEMPTS:\n",
        "    # Get the current loaded elements count\n",
        "    app_elements = get_current_app_elements()\n",
        "    current_data_count = len(app_elements)\n",
        "\n",
        "    # Print current count\n",
        "    print(f\"Attempt {attempts + 1}: Loaded elements = {current_data_count}\")\n",
        "\n",
        "    # If no new content is loaded after scrolling, increase the attempt counter\n",
        "    if current_data_count == previous_data_count:\n",
        "        attempts += 1\n",
        "    else:\n",
        "        attempts = 0  # Reset attempts if new content is loaded\n",
        "        previous_data_count = current_data_count\n",
        "\n",
        "    # Scroll down by a small increment\n",
        "    driver.execute_script(\"window.scrollBy(0, arguments[0]);\", SCROLL_INCREMENT)\n",
        "    time.sleep(SCROLL_PAUSE_TIME)\n",
        "\n",
        "print(f\"Page loading completed. Total number of applications loaded: {previous_data_count}\")\n",
        "\n",
        "# Extract data from the fully loaded page\n",
        "app_elements = get_current_app_elements()\n",
        "\n",
        "# Iterate over each app container\n",
        "for rank, element in enumerate(app_elements, start=1):\n",
        "    # Extract the app title\n",
        "    try:\n",
        "        app_title_elem = element.find_element(By.XPATH, './/a[contains(@class, \"s-4262409-0\")]')\n",
        "        app_title = app_title_elem.get_attribute('title').strip() if app_title_elem else None\n",
        "    except Exception as e:\n",
        "        app_title = None\n",
        "\n",
        "    # Extract the developer account name\n",
        "    try:\n",
        "        developer_account_elem = element.find_element(By.XPATH, './/div[contains(@class, \"s1376732636-0\")]')\n",
        "        developer_account_text = developer_account_elem.text.strip()\n",
        "        developer_account = developer_account_text.split(\"·\")[-1].strip() if \"·\" in developer_account_text else developer_account_text\n",
        "    except Exception as e:\n",
        "        developer_account = None\n",
        "\n",
        "    # Extract the app link for detailed page\n",
        "    try:\n",
        "        app_link_elem = element.find_element(By.XPATH, \".//a[contains(@class, 's-4262409-0')]\")\n",
        "        app_link = app_link_elem.get_attribute('href').strip() if app_link_elem else None\n",
        "        if app_link and not app_link.startswith('http'):\n",
        "            app_link = driver.current_url.rsplit('/', 1)[0] + '/' + app_link\n",
        "    except Exception as e:\n",
        "        app_link = None\n",
        "\n",
        "    ios_app_store_id = None\n",
        "    estimated_downloads = None\n",
        "    estimated_revenue = None\n",
        "\n",
        "    # If app link is available, open in a new tab to get detailed information\n",
        "    if app_link:\n",
        "        driver.execute_script(\"window.open('');\")\n",
        "        driver.switch_to.window(driver.window_handles[-1])\n",
        "        driver.get(app_link)\n",
        "        time.sleep(5)  # Wait for the page to load fully\n",
        "\n",
        "        # Parse page source with BeautifulSoup\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "        # Extract iOS App Store ID using BeautifulSoup\n",
        "        try:\n",
        "            ios_app_store_id_elem = soup.select_one(\"span.s-1674543659-0.s1901059984-1\")\n",
        "            ios_app_store_id = ios_app_store_id_elem.get_text().strip() if ios_app_store_id_elem else None\n",
        "        except Exception as e:\n",
        "            ios_app_store_id = None\n",
        "\n",
        "        # Extract Estimated Downloads using XPath\n",
        "        try:\n",
        "            estimated_downloads_elem = driver.find_element(\n",
        "                By.XPATH,\n",
        "                '//*[@id=\"react-components-overlay-provider-root\"]/span/span/div/div/div[1]/div[3]/div[1]/div[2]/div[1]/div[1]/div/div[2]/div[1]/div'\n",
        "            )\n",
        "            estimated_downloads = estimated_downloads_elem.text.strip() if estimated_downloads_elem else None\n",
        "        except Exception as e:\n",
        "            estimated_downloads = None\n",
        "\n",
        "        # Extract Estimated Revenue using XPath\n",
        "        try:\n",
        "            estimated_revenue_elem = driver.find_element(\n",
        "                By.XPATH,\n",
        "                '//*[@id=\"react-components-overlay-provider-root\"]/span/span/div/div/div[1]/div[3]/div[1]/div[2]/div[1]/div[2]/div/div[2]/div[1]/div'\n",
        "            )\n",
        "            estimated_revenue = estimated_revenue_elem.text.strip() if estimated_revenue_elem else None\n",
        "        except Exception as e:\n",
        "            estimated_revenue = None\n",
        "\n",
        "        driver.close()  # Close the detailed page tab\n",
        "        driver.switch_to.window(driver.window_handles[0])  # Switch back to the main tab\n",
        "\n",
        "    # Append data to the list\n",
        "    scraped_data.append({\n",
        "        'scraping_url': base_url,\n",
        "        'scraping_timestamp': pd.Timestamp.now(),\n",
        "        'country': 'United States',\n",
        "        'device': 'iPhone',\n",
        "        'category': 'Top Overall',\n",
        "        'segment': 'Free',  # Fixed to \"Free\" since this is the \"top-free\" category\n",
        "        'rank': rank,\n",
        "        'app_title': app_title,\n",
        "        'developer_account': developer_account,\n",
        "        'app_link': app_link,\n",
        "        'ios_app_store_id': ios_app_store_id,\n",
        "        'estimated_downloads': estimated_downloads,\n",
        "        'estimated_revenue': estimated_revenue\n",
        "    })\n",
        "\n",
        "    # Print statement for progress\n",
        "    print(f\"Rank: {rank}, App Title: {app_title}\")\n",
        "\n",
        "# Close the driver\n",
        "driver.quit()\n",
        "\n",
        "# Create a pandas DataFrame from the scraped data\n",
        "df = pd.DataFrame(scraped_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "RWZh5qYCgTUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}